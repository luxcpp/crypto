---
title: Metal Backend
description: GPU acceleration via Apple Metal compute shaders
---

# Metal Backend

The Metal backend provides GPU acceleration for cryptographic operations on Apple Silicon, leveraging the unified memory architecture for efficient data transfer.

## Requirements

- **macOS 11.0+** or **iOS 14.0+**
- **Apple Silicon** (M1/M2/M3) or AMD GPU
- **Metal 3** support recommended

## Architecture

```
┌─────────────────────────────────────────────────────────────┐
│                    C++ API Layer                             │
│              (bls.cpp, mldsa.cpp, hash.cpp)                  │
├─────────────────────────────────────────────────────────────┤
│                 Objective-C++ Bridge                         │
│           (metal_bls.mm, metal_hash.mm, etc.)                │
├─────────────────────────────────────────────────────────────┤
│                  Metal Compute Shaders                       │
│              (bls.metal, hash.metal, ntt.metal)              │
├─────────────────────────────────────────────────────────────┤
│                   Metal Framework                            │
│            (Command Queues, Buffers, Pipelines)              │
├─────────────────────────────────────────────────────────────┤
│                  Apple GPU Hardware                          │
│                (M1/M2/M3 GPU Cores)                          │
└─────────────────────────────────────────────────────────────┘
```

## Shader Implementation

### Field Arithmetic

Montgomery multiplication for BLS12-381:

```metal
// 384-bit Montgomery multiplication on GPU
kernel void mont_mul_384(
    device const uint32_t* a [[buffer(0)]],
    device const uint32_t* b [[buffer(1)]],
    device uint32_t* result [[buffer(2)]],
    constant uint32_t* modulus [[buffer(3)]],
    constant uint32_t& inv [[buffer(4)]],
    uint tid [[thread_position_in_grid]]
) {
    // Each thread handles one multiplication
    uint32_t t[24];  // 768-bit intermediate

    // Schoolbook multiplication
    for (int i = 0; i < 12; i++) {
        uint64_t carry = 0;
        for (int j = 0; j < 12; j++) {
            uint64_t prod = (uint64_t)a[tid * 12 + i] * b[j] + t[i + j] + carry;
            t[i + j] = (uint32_t)prod;
            carry = prod >> 32;
        }
        t[i + 12] = (uint32_t)carry;
    }

    // Montgomery reduction
    mont_reduce(t, modulus, inv);

    // Store result
    for (int i = 0; i < 12; i++) {
        result[tid * 12 + i] = t[i];
    }
}
```

### Multi-Scalar Multiplication (MSM)

Pippenger's algorithm optimized for GPU:

```metal
// Bucket accumulation for MSM
kernel void msm_bucket_accumulate(
    device const Point* points [[buffer(0)]],
    device const Scalar* scalars [[buffer(1)]],
    device Point* buckets [[buffer(2)]],
    constant uint& window_size [[buffer(3)]],
    constant uint& window_idx [[buffer(4)]],
    uint tid [[thread_position_in_grid]],
    uint tcount [[threads_per_grid]]
) {
    // Extract window from scalar
    uint window = extract_window(scalars[tid], window_idx, window_size);

    if (window != 0) {
        // Atomic add to bucket
        atomic_point_add(buckets + window, points[tid]);
    }
}

// Bucket reduction
kernel void msm_bucket_reduce(
    device Point* buckets [[buffer(0)]],
    device Point* result [[buffer(1)]],
    constant uint& num_buckets [[buffer(2)]],
    uint tid [[thread_position_in_grid]]
) {
    // Running sum reduction
    Point running_sum = point_identity();
    Point total = point_identity();

    for (int i = num_buckets - 1; i >= 0; i--) {
        running_sum = point_add(running_sum, buckets[tid * num_buckets + i]);
        total = point_add(total, running_sum);
    }

    result[tid] = total;
}
```

### Number Theoretic Transform (NTT)

Radix-2 NTT for polynomial operations:

```metal
// NTT butterfly operation
kernel void ntt_butterfly(
    device int32_t* poly [[buffer(0)]],
    constant int32_t* twiddles [[buffer(1)]],
    constant uint& layer [[buffer(2)]],
    constant int32_t& modulus [[buffer(3)]],
    uint tid [[thread_position_in_grid]]
) {
    uint step = 1 << layer;
    uint block = tid / step;
    uint j = tid % step;
    uint i = block * (step << 1) + j;

    int32_t u = poly[i];
    int32_t v = mont_mul(twiddles[step + j], poly[i + step], modulus);

    poly[i] = mod_add(u, v, modulus);
    poly[i + step] = mod_sub(u, v, modulus);
}
```

### BLAKE3 Parallel Hashing

```metal
// BLAKE3 chunk processing
kernel void blake3_chunks(
    device const uint8_t* input [[buffer(0)]],
    device uint32_t* chunk_outputs [[buffer(1)]],
    constant uint32_t& input_len [[buffer(2)]],
    uint tid [[thread_position_in_grid]]
) {
    uint chunk_start = tid * BLAKE3_CHUNK_LEN;
    if (chunk_start >= input_len) return;

    uint chunk_len = min(BLAKE3_CHUNK_LEN, input_len - chunk_start);

    // Initialize chunk state
    uint32_t cv[8] = {
        IV[0], IV[1], IV[2], IV[3],
        IV[4], IV[5], IV[6], IV[7]
    };

    // Process blocks in chunk
    uint block_count = (chunk_len + 63) / 64;
    for (uint b = 0; b < block_count; b++) {
        uint32_t block[16];
        load_block(block, input + chunk_start + b * 64);

        uint32_t flags = CHUNK_START * (b == 0) | CHUNK_END * (b == block_count - 1);
        compress(cv, block, tid, b, flags);
    }

    // Store chunk output
    for (int i = 0; i < 8; i++) {
        chunk_outputs[tid * 8 + i] = cv[i];
    }
}
```

## Memory Management

### Buffer Allocation

```cpp
// Create Metal buffer from host data
MTL::Buffer* create_buffer(const void* data, size_t size) {
    return device->newBuffer(data, size,
        MTL::ResourceStorageModeShared);  // Unified memory
}
```

### Unified Memory

Apple Silicon's unified memory architecture eliminates CPU-GPU data transfer overhead:

```cpp
// Zero-copy access
auto buffer = device->newBuffer(
    size,
    MTL::ResourceStorageModeShared
);

// Both CPU and GPU can access directly
uint8_t* ptr = (uint8_t*)buffer->contents();
```

## Configuration

### Device Selection

```cpp
// Get default GPU device
auto device = MTL::CreateSystemDefaultDevice();

// List all available devices
auto devices = MTL::CopyAllDevices();
for (auto& dev : devices) {
    std::cout << dev->name() << std::endl;
}
```

### Compile Options

```cmake
# Enable Metal backend
set(LUX_CRYPTO_METAL ON)

# Metal shader compilation
add_custom_command(
    OUTPUT ${CMAKE_BINARY_DIR}/shaders.metallib
    COMMAND xcrun -sdk macosx metallib
            -o ${CMAKE_BINARY_DIR}/shaders.metallib
            ${SHADER_SOURCES}
    DEPENDS ${SHADER_SOURCES}
)
```

## Performance Tuning

### Thread Configuration

```cpp
// Optimal thread group size for M1
MTL::Size threadGroupSize = MTL::Size(256, 1, 1);

// Calculate grid size
size_t numElements = ...;
size_t gridWidth = (numElements + 255) / 256;
MTL::Size gridSize = MTL::Size(gridWidth * 256, 1, 1);

encoder->dispatchThreads(gridSize, threadGroupSize);
```

### Concurrent Operations

```cpp
// Create multiple command buffers for concurrent operations
std::vector<MTL::CommandBuffer*> buffers;
for (int i = 0; i < num_operations; i++) {
    auto buffer = queue->commandBuffer();
    // Encode operations
    buffer->commit();
    buffers.push_back(buffer);
}

// Wait for all to complete
for (auto& buffer : buffers) {
    buffer->waitUntilCompleted();
}
```

## Error Handling

```cpp
// Check for Metal errors
MTL::CommandBuffer* buffer = queue->commandBuffer();
buffer->addCompletedHandler([](MTL::CommandBuffer* buf) {
    if (buf->status() == MTL::CommandBufferStatusError) {
        std::cerr << "Metal error: "
                  << buf->error()->localizedDescription()->utf8String()
                  << std::endl;
    }
});
```

## Limitations

1. **Platform**: macOS/iOS only
2. **Minimum Version**: macOS 11.0 / iOS 14.0
3. **Small Inputs**: CPU may be faster for very small operations
4. **Latency**: GPU dispatch has fixed overhead (tens of microseconds)

## Benchmarks

Detailed benchmarks on Apple M1 Max (32 GPU cores):

| Operation | Time | Throughput |
|-----------|------|------------|
| BLS Sign (batch 1000) | 67ms | 14,925/s |
| BLS Verify (batch 1000) | 125ms | 8,000/s |
| MSM 2^16 points | 25ms | 40/s |
| BLAKE3 1GB | 83ms | 12.0 GB/s |
| NTT 2^20 | 8ms | 125/s |
| ML-DSA-65 Sign | 40μs | 25,000/s |
